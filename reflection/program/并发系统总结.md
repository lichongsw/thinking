# 按自己的理解记忆

对并发的理解随着工作内容的变化也有一些新的看法，算是一直在沉淀。这里结合工作经历来记录自己思考的变化。在早期的安防领域工作经验中，系统讲究的是实时性和可靠性，在给定时间范围内必须处理完某些时间，这是由国家的行业标准规定的。系统虽然也不小，主机控制节点数过万，这相当于业务同时在线人数过万。要想想主机是主频800MHZ的单核芯片加上256M的内存，这跟常见的业务系统主机的强大多核CPU和动辄几十G的内存是两个完全不同的环境。这个精致的小型系统中，有几点设计是值得提及的：

1. 以message based的单IO线程异步接收消息，这在现代化的编程中广泛使用，。
2. 以active queue为基础的thread based的多线程应用层通过队列通信，能够通过添加新的Access point来扩展应用功能。这跟现代化编程中的微服务概念相似，尽量避免共享内存和探知其他平级服务的内部知识。
3. 以抢占式线程调度，QoS的网络通信，高低优先级两条并行的回路来确保实时性，在每一个环节都确保高优先级事件优先得到处理。这在现代化的编程中基本是看不到的，这个设计要付出的代价太高昂。普通的民用业务系统不需要这样强的实时性。
4. 可靠性基本是通过冗余的硬件来保证，也是主从切换这一套做法。
5. 系统使用C++语言，没有GC的STW。所有内存都在启动期间申请并池化，启动完成后没有任何动态内存。这中极其严格的做法牺牲了开发效率但极大程度的提升了系统的稳定性，这也与面向普通业务的编程是不符的。不夸张的说，很多人不一定清楚没有动态内存意味着什么。

来到互联网行业，并发的难度确实被放大了很多。多核，多机器，流量高峰等将整个战场的等级提升了几个数量级。对比来看也就网络和IO这块的模型没有什么变化，这是因为协议栈和异步多路复用实在太稳定，以至于10年时间里还是差不多的样子。

## 处理并发的通用思路

高并发的能力可以简单理解为系统在一段时间里面的吞吐量。这个一段时间的概念是很重要的，没有任何系统能够稳定持续处理超过系统的吞吐量的任务，这个就算是以100%的效率来工作也是无济于事的。

1. 提升单机性能，就是换更牛逼的设备。这个解决办法最简单好用，其最大的问题就是收益与投资不成比例。除开部分头部公司的业务，小型企业的业务量如果稳定而且不会有太多增长完全可以这么做，效果决立竿见影，根本不需要去折腾其他方案。对于中型业务量的公司这招以后可能没那么好用了，因为硬件的提升空间不像以前那么大了。
2. 使用分布式的系统，用多个便宜的主机来水平扩展吞吐量。这个方式应该是大部分头部公司的选择，毕竟成本低。流量高峰只是短期而且在特定时刻可以预测的，例如各种节假日和活动都是可以按照你是数据来预估的，这样用不完的量就能以多租户的方式租出去收取租金。拥有大量主机的公司基本都有云业务，一方面自己要用，而且还可以在闲时找人分摊成本。分布式那就有得折腾了，这个打算用一篇单独的文章来讲。
3. 缓存和，是以不稳定的服务质量来换取处理时间。CPU跟内存之间有缓存，内存跟硬盘之间也有缓存，一环套一环来提高低速部件的使用效率。缓存没有命中的时候就慢一点，缓存命中了那就很快。本质上还是系统各个组件之间的匹配程度问题。
4. 异步服务基本上是普通民用业务的首选策略，以可以接受的服务质量来处理事情。大部分场景下没有人会在乎你是10毫秒还是100毫秒搞定用户的一件事情，甚至于大部分场景里都是秒级别的。这样系统就可以收集一大波请求，集中时间批量处理来提高运转效率。异步基本上就是各种队列和回调，先收着积压起来处理好了再通知。但我个人觉得这里异步的吞吐量有点伪命题的意思，如果系统积压的量超出某个限定后告诉用户失败其实这可能不能算作吞吐量的。比如秒杀100个低价商品，就算队列积压了1000条请求其实只执行了100额商品的买卖业务逻辑，后面的全部都直接打回去了。

就拿去宜家家居买东西来做比喻描述上面几个方法（上个月刚去佛山旗舰店）：
scale up是把店面建成旗舰店，面积大展区多收银台多服务区人手多。边逛边体验，喜欢的就丢到购物车，逛完去收银台买单去服务台开发票走人，无论哪个环节顾客几乎都不用等。
scale out 就是一家店不够就开多几家，把顾客分流到不同的店里去，尽量让各个分店的体验接近旗舰店。
cache 缓存的理解跟文章不一样，缓存的基础是系统有热点，有少数东西的使用率特别高。对宜家的例子来说缓存就像top10的热卖商品的专用摊位，整个店里有几个关键的路口都有摆上。这些销量占比非常大的产品顾客很容易扔进购物车，而不需要像购买普通商品那样跑到哪层楼哪个区哪个货架才能拿到，这加速了顾客的购买过程。
asyn 异步这个话题有点大。理解估计也有不少偏差，明确的说目前服务器上用的最好的linux的epoll是同步的，可以选择阻塞或者不阻塞。真正的异步IO实现有linux的aio（出来的晚，目前还不好用）和windows的IOCP。对于宜家来讲开纸质发票就是同步的，一堆人排队把小票给服务人员后在服务台等机器出发票。而开电子发票是异步的，顾客直接回家，想开票的时候扫描小票上的二维码填写发票信息，等会电子发票弄好了就发到邮箱了。

不管手段如何，适合公司当前业务量的系统才是最重要的。随着业务的成长赚到钱了，一定有重构系统的机会（资金和人才以及想赚更多的钱）。如果都按照百万、千万并发来设计系统，电商一律向淘宝看齐，IM全都学习微信和QQ，你没有那么牛逼的工程师和业务量，根本驾驭不了复杂的系统。

## 架构分层

不要看到分层就想到MVC之类的概念，那是一个狭义的例子。说大一点有应用层、控制层、和数据处理。再看看领域驱动设计这本书就会有更多的体会，牛逼的系统应该是深刻理解业务的架构师们锤炼出来的。复杂的系统基本上都要组件化，然后不同的组件也有不同的层次，上层的工作依赖于下层。像协议栈短小精悍，防火主机庞大系统的的IO以及Application层都是为了降低系统的复杂度和尽量保持可复用的组件来适应变化。不足的地方是有一定的复杂性，一个需求可能涉及到全部层次的模块的小范围更新，熟悉系统的人可能做起来比较容易，新进的成员需要一段时间来理解分层带来的复杂性。

## 指标

高并发系统设计的三大目标：高性能、高可用、可扩展。性能反应了系统的使用体验，就是系统的客户的第一感觉。你自己开车，车加速，操控如何都是驾驶员能够感受的到的。可用就是车子正常保养，几乎或者很少掉链子，不会把你丢在路上。扩展就是平时就你一个人开车上下班，但真到周末了一大家子人出去的时候还能够坐得舒服，最好还能加个车顶行李箱之类轻松搞定一家子的行李。

1. 性能是够用就好，不要盲目的折腾。一般来讲肯定是某个地方出现瓶颈限制了性能，最好针对瓶颈做优化满足量化的性能指标即可。这是一个长期的过程，还是问题或者说是风险驱动的。就给定吞吐量的情况下谈指标，平均值不敏感，最大值又过于敏感，分位值反应的要略清楚一些。在请求完全是并行的情况下，增加服务的进程可以获得良好的性能提升，但这也有个限度就是多进程消耗了过多的资源后造成系统繁忙反而会导致整体性能下降，这个要依靠性能测试。另外一种比较难的做法就是减少任务的单词执行时间，CPU密集型的就要靠算法了，IO密集型要靠各种缓存和池化技术以及查看绨IO耗时过久的原因。
有个老哥讲的非常好，简直不能更加同意了：
>
业务价值->承载高并发->性能优化。一切的前提是业务价值需要。如果没有足够的价值，那么可读性才是第一，性能在需要的地方是no.1，但不需要的地方可能就是倒数第一稞。当下技术框架出来的软件差不到哪去，没有这种及时响应诉求的地方，削峰下慢慢跑就是了。（工作需要，常在缺少价值的地方着手性能优化，让我对这种就为个数字的操作很反感。要知道，异步，并发编程，逻辑缓存，算法真的会加剧系统的复杂度，得不偿失。如果没那个价值，简单才是王道）

提高并发度。要么加硬件，要么降低服务响应时间。做为开发，我们的目光更聚焦在降低响应时间这块。
1.采用非阻塞的rpc调用（高效的远端请求模式，采用容器的覆盖网络我认为也算）
2.将计算密集和io密集的的逻辑分割开，单独线程池，调整线程比例压榨单机性能（或者说找拐点）。
3.做缓存，io耗时的缓存和计算耗时的缓存（多级缓存，数据压缩降低带宽）。
4.采用享元模式，用好对象池和本地线程空间，尽量减少对象创建与销毁的开销，提高复用。
5.业务拆分，像状态变化后的外部系统通知，业务监控，es或solr等副本数据同步等操作，无需在主流程中做的事都拆掉。走canal监听表数据变化，推mq保最终一致的方式从业务项目完全解偶出来。
6.fork_join，分而治之的处理大任务。并发编程，采用多线程并行的方式处理业务。（规避伪共享，减小锁力度，采用合适的锁）。
7.数据库配置优化，查询优化。（存储优化比较头疼，毕竟不按业务拆单点跑不掉，单点性能就要命。基本只能内存库先行，后台同步数据做持久。然后内存库多副本，自修复，保留一系列自修复失败的修复手段）
